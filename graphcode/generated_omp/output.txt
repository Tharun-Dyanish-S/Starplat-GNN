Here half
num_features 48
num Nodes3
nodes size 3
features size 16
labels size 2
going to preprocessing
omp
Neurons initially 16
layer with size 8 initialized
layer with size 2 initialized
xavier distribution with input neurons : 16 and output neurons : 8
xavier distribution with input neurons : 8 and output neurons : 2
Layers initialized
y_pred : 0
y_pred : 1
y_pred : 0
Accuracy: 0.333333
1
y_pred : 0
y_pred : 1
y_pred : 0
Accuracy: 0.333333
2
y_pred : 0
y_pred : 1
y_pred : 0
Accuracy: 0.333333
3
y_pred : 0
y_pred : 1
y_pred : 0
Accuracy: 0.333333
4
y_pred : 0
y_pred : 1
y_pred : 0
Accuracy: 0.333333
5
y_pred : 0
y_pred : 1
y_pred : 0
Accuracy: 0.333333
6
y_pred : 0
y_pred : 1
y_pred : 0
Accuracy: 0.333333
7
y_pred : 0
y_pred : 1
y_pred : 0
Accuracy: 0.333333
8
y_pred : 0
y_pred : 1
y_pred : 0
Accuracy: 0.333333
9
Accuracy: 0.333333
Layer 1 weights
0.0907055	-0.293275	0.0545039	-0.249286	0.214889	-0.0658552	0.232552	-0.321193	
0.352661	0.32657	-0.414847	0.0858713	0.162442	-0.0939533	0.0865887	0.267024	
-0.296493	-0.122731	-0.0384202	0.0622827	0.393525	-0.130638	0.379653	-0.468021	
-0.304968	-0.477404	0.177763	-0.338331	0.201941	0.48147	0.472086	0.0447122	
0.362915	-0.205444	0.0461193	-0.347971	-0.270357	0.393685	0.00378495	0.233167	
0.151811	0.468762	-0.0409047	0.42873	-0.0503057	-0.316202	0.186359	0.200563	
-0.397673	0.303506	0.000799303	-0.175304	-0.283537	0.314108	-0.291023	-0.399284	
0.34538	0.214425	0.416778	0.0590951	-0.205554	0.0434359	0.468303	-0.222675	
-0.340221	-0.34465	-0.184626	-0.349498	-0.217515	0.399514	-0.327842	0.417562	
-0.00111577	0.422773	0.0996515	-0.167606	0.00713427	-0.357494	-0.307374	0.316264	
-0.296069	0.140698	-0.2609	-0.0754286	-0.135975	-0.366691	0.273753	-0.196433	
0.281932	-0.408864	0.288108	-0.0694113	0.474157	-0.459954	0.15036	0.140761	
-0.137467	-0.102918	-0.103065	0.42482	0.475755	0.397006	0.35043	0.456171	
0.142223	0.113584	-0.249934	0.0216468	0.379293	0.0965376	-0.271272	-0.0854224	
0.20817	0.148912	-0.339375	-0.0634485	0.0319457	-0.125981	-0.228728	-0.22076	
-0.0405108	0.0700704	0.0646825	0.0387938	0.271299	-0.171364	0.267272	-0.498778	
Layer 1 aggregated features
0.343619	0.498526	0.653434	0.423341	0.812423	0.21899	0.373897	0.528804	6.33712	2.83619	3.83526	4.83434	5.83341	6.42424	3.7899	4.78897	
0.419368	0.456035	0.85196	0.574275	1.03076	0.223712	0.484915	0.521582	7.86868	3.66296	5.37685	7.58063	6.60008	7.98063	4.03341	7.05369	
0.398619	0.333526	0.708434	0.643341	0.817423	0.10399	0.313897	0.248804	5.13712	3.93619	5.48526	7.63434	5.88341	7.02424	1.6399	4.78897	
Layer 1 pre activated features
-0.979486	-1.4504	-3.5672	-1.12097	7.09689	-0.0341128	0.295772	2.05937	
-1.18841	-2.38486	-3.7348	-1.825	9.4682	-1.34564	0.897112	1.96484	
-0.865746	-2.05657	-2.28864	-1.19007	8.7818	-2.33311	1.55846	2.40917	
Layer 1 post activated features
0	0	0	0	7.09689	0	0.295772	2.05937	
0	0	0	0	9.4682	0	0.897112	1.96484	
0	0	0	0	8.7818	0	1.55846	2.40917	
Layer 1 grad pre act output
-0	0	0	-0	18.9958	-6.22032	7.91903	7.18007	
-0	0	0	-0	24.6611	-0	10.7438	8.72729	
-0	0	0	-0	21.7861	-0	9.08223	8.23472	
Layer 1 grad post act output
0	0	0	0	0	0	0	0	
0	0	0	0	0	0	0	0	
0	0	0	0	0	0	0	0	
Layer 1 grad weights
0	0	0	0	8.51791	-0.712473	3.61569	3.13656	
0	0	0	0	9.32749	-1.03366	3.95885	3.4353	
0	0	0	0	16.2856	-1.35485	6.92066	5.98692	
0	0	0	0	12.0733	-0.877772	5.12177	4.44974	
0	0	0	0	19.5536	-1.68451	8.31065	7.18676	
0	0	0	0	3.9808	-0.454062	1.69405	1.46036	
0	0	0	0	8.6332	-0.775253	3.67387	3.16715	
0	0	0	0	9.44277	-1.09644	4.01703	3.46589	
0	0	0	0	127.904	-11.8257	54.4139	46.9428	
0	0	0	0	68.9887	-5.2926	29.269	25.4236	
0	0	0	0	97.4865	-7.15697	41.3873	35.8897	
0	0	0	0	133.53	-9.02133	56.7194	49.1207	
0	0	0	0	120.526	-10.8857	51.1618	44.38	
0	0	0	0	141.563	-11.9882	60.1235	52.0855	
0	0	0	0	62.1562	-7.07231	26.4721	22.775	
0	0	0	0	110.776	-8.93668	47.1606	40.6142	
Layer 2 weights
0.718836	0.212137	
-0.453012	0.568044	
-0.394069	-0.171197	
0.519294	-0.0355935	
-0.693536	-0.291006	
0.226981	-0.393636	
-0.289176	-0.584403	
-0.262193	0.484078	
Layer 2 aggregated features
0	0	0	0	40.9685	1.22564	6.067	8.68724	
0	0	0	0	53.4732	1.11313	9.78518	11.9198	
0	0	0	0	45.8933	0.41323	9.51133	9.60647	
Layer 2 pre activated features
-32.1679	0	
-42.7887	0	
-37.0049	0	
Layer 2 post activated features
2.91026e-14	2.71828	
7.1022e-19	2.71828	
2.30819e-16	2.71828	
Layer 2 grad pre act output
-27.3932	0	
-35.1432	-1	
-31.4168	0	
Layer 2 grad post act output
0	0	
0	0	
0	0	
Layer 2 grad weights
0	0	
0	0	
0	0	
0	0	
-1214.03	-14.6116	
-28.5585	-0.371042	
-240.57	-2.90972	
-252.775	-3.14686	
